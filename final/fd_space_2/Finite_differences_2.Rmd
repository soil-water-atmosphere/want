---
title: "Finite differences 2 - FD in space"
author: "The WANT team"
date: "24/09/2018"
output:
  html_document:
    css: ../../want.css
    toc: yes
    toc_depth: 2
---
<!-- include the hint.js -->
<script src="../../hints.js"></script>

# Learning goals
* Understand the forward, backward and central spatial differencing scheme *(Section 1)*
* Understand how to construct a matrix to solve a system of equations *(Section 2)*
* Understand how to solve a steady-state system with spatial derivatives using matrix algebra *(Section 3)*
* Understand the advection-diffusion equation and how to solve a stationary form *(Section 4)*

# Part 1 - Introduction
## Section 1.1 - Advection Diffusion Equation 
The aim of the finite difference approach is to learn a basic method to discretize differential equations in space and time. A prominent example in our field, is the advection-diffusion equation. The formula for this equation is as follows:

$$\frac{\partial s}{\partial t} = -u \frac{\partial s}{\partial x} + D\frac{\partial^{2}s}{\partial x^{2}}$$
where $s$ can be any species that can be transported, $u$ is the fluid (water or air) velocity, $D$ is the diffusivity, $x$ is the position, and $t$ is time. This equation contains space and time derivatives and is therefore a *partial differential equation*. For this tutorial, you will study first this equation under stationary conditions ($\frac{\partial s}{\partial t} = 0$):

$$0 = -u \frac{\partial s}{\partial x} + D\frac{\partial^{2}s}{\partial x^{2}}$$
Before that, you will first work yourself through the theory needed to do so.

## Section 1.2 - Backward and Central Differencing method
In the previous practical, we have been working with the following formula:
$$\dfrac{ds}{dt} \approx \dfrac{s(t+\Delta t) - s(t)}{\Delta t}$$
This is called the *forward differencing method*. It calculates derivatives based on the actual time value ($t$) and that one step ahead ($t + \Delta t$) The methodology of solving equations in space is exactly the same, only the mathematical formulation changes slightly:

$$\dfrac{ds}{dx} \approx \dfrac{s(x+\Delta x) - s(x)}{\Delta x}$$
The only change in this equation is that time has been substituted by space. By using this formulation you change the dimension, meaning that you will find out the how fast variable $s$ changes in space rather than in time.

There is generally a difference in perspective in how space and time are used. In the case of time, you use the derivative to advance a system in time: you want to know the state of the system $s$ at a next time step. In space, however, in most cases, you are presented with the spatial field of $s$, where the gradients are unknown. You often need these spatial gradients for your model calculations. In space, next to the forward differencing methods, we also often make use of the *backward differencing method* and the *centered differencing* method.

First, we will go through the mathematical derivation. The forward differencing method in space, uses the location at which the derivatives are calculated and the point right (forward in space) of it:

$$s(x + \Delta x) = s(x) + \Delta x \frac{ds}{dx} \bigg\rvert_{x} + \frac{\Delta x^{2}}{2!} \frac{d^{2}s}{dx^{2}} \bigg\rvert_{x} + \frac{\Delta x^{3}}{3!} \frac{d^{3}s}{dx^{3}} \bigg\rvert_{x} + \frac{\Delta x^{4}}{4!} \frac{d^{4}s}{dx^{4}} \bigg\rvert_{x} + \ \cdots     $$

The backward scheme looks back along the space axis (in negative direction) and is defined as follows:

$$s(x - \Delta x) = s(x) - \Delta x \frac{ds}{dx} \bigg\rvert_{x} + \frac{\Delta x^{2}}{2!} \frac{d^{2}s}{dx^{2}} \bigg\rvert_{x} - \frac{\Delta x^{3}}{3!} \frac{d^{3}s}{dx^{3}} \bigg\rvert_{x} + \frac{\Delta x^{4}}{4!} \frac{d^{4}s}{dx^{4}} \bigg\rvert_{x} - \ \cdots     $$

Reworking this equation leads to the backward differencing scheme:

$$\frac{s(x) - s(x  - \Delta x)}{dx} = \frac{ds}{dx} + \cdots$$

The *central differencing scheme* is created by substracting the Taylor series used for the forward and backward schemes. It is called centered because it is symmetric. It uses one point forward (right) of where the derivative is calculated, and one point (left) backward.

\begin{alignat*}{3}
s(x + \Delta x) &= s(x) + && \dfrac{\Delta x}{1!} \dfrac{ds}{dx} \bigg\rvert_{x} + \dfrac{\Delta x^{2}}{2!} \dfrac{d^{2}s}{dx^{2}} \bigg\rvert_{x} + &&& \dfrac{\Delta x^{3}}{3!} \dfrac{d^{3}s}{dx^{3}} \bigg\rvert_{x} + \dfrac{\Delta x^{4}}{4!} \dfrac{d^{4}s}{dx^{4}} \bigg\rvert_{x} + \ ... \\    


s(x - \Delta x) &= s(x) - && \dfrac{\Delta x}{1!} \dfrac{ds}{dx} \bigg\rvert_{x} + \dfrac{\Delta x^{2}}{2!} \dfrac{d^{2}s}{dx^{2}} \bigg\rvert_{x} - &&&\dfrac{\Delta x^{3}}{3!} \dfrac{d^{3}s}{dx^{3}} \bigg\rvert_{x} + \dfrac{\Delta x^{4}}{4!} \dfrac{d^{4}s}{dx^{4}} \bigg\rvert_{x} - \ ...  \\

\hline \\

s(x + \Delta x) - s(x - \Delta x) &=  &&\dfrac{2\Delta x}{1!}\dfrac{ds}{dx} +  &&&\dfrac{2\Delta x^{3}}{3!} \dfrac{d^{3}s}{dx^{3}}
\end{alignat*}

It can be seen quite easily that this is an efficient scheme. The second and fourth derivative are canceled out by substraction, leaving an error term in the final equation that has the third derivative as largest contributor instead of the second. This reduces the error significantly. The final equation to express the first derivative is as follows:

$$\frac{s(x + \Delta x) - s(x - \Delta x)}{2\Delta x} = \frac{ds}{dx} + \cdots$$
<span class="exercise">
1.2.1 Give for each of the approximations the first error term (the next term that should come at the $\ldots$).
<br><br>
1.2.2 Can you explain from the error why the forward and backward differencing method have first-order error convergence, and the centered scheme has second-order error convergence?
</span>

<div class="answer">
For both the forward and backward scheme, the first error term equals:
$$ \frac{\Delta x^{2}}{2!} \frac{d^{2}s}{dx^{2}} \frac{1}{\Delta x} = \frac{\Delta x}{2!} \frac{d^{2}s}{dx^{2}}$$

For the centered scheme, the second derivative is eliminated and the first (largest) error term is only formed by the third derivative:
$$ \dfrac{2\Delta x^{3}}{3!} \dfrac{d^{3}s}{dx^{3}} \frac{1}{2\Delta x} = \dfrac{\Delta x^{2}}{3!} \dfrac{d^{3}s}{dx^{3}}$$
</div>

In order to visualize the effects of the three different approximations, you will now implement each of them for an example containing a *standing wave*. You will compute the derivatives of $s(x) = \sin(x)$. This you will do for each of the three methods: forward, backward, and centered.

<span class="exercise">
1.2.3 Implement the calculations for the three different methods below.
<br><br>
1.2.4 Which of the three methods performs the best?
<br><br>
1.2.5 Decrease `dx` in steps. Do all three methods converge to the correct result? Which one converges fastest, and why?
</span>

<span class="student_answer">
Work out the code below.
```{r eval=FALSE}
# Initial parameter values
left  = 0     # left x-coordinate
right = 2*pi  # right x-coordinate
dx    = pi/6  # delta x; space discretisation

# Simulation initialisation
space.sequence = seq(left, right, by=dx)
dsdx.forward  = rep(0, length(space.sequence)) #derivative with forward method
dsdx.backward = rep(0, length(space.sequence)) #derivative with backward method
dsdx.centered = rep(0, length(space.sequence)) #derivative with centered method
s = sin(space.sequence)

# Add the calculations of forward, backward, centered derivative below (filling the three dsdx vectors)

# Plotting
plot(space.sequence, dsdx.forward, type='o', xlab="x (m)", ylab="dsdx", ylim = c(-1.5, 1.5), col="blue")
lines(space.sequence, dsdx.backward, type='o', col="red")
lines(space.sequence, dsdx.centered, type='o', col="green")
space.sequence = seq(left, right, by=0.01)
analyt.state = cos(space.sequence)
lines(space.sequence, analyt.state, col='black', lty=3)
legend("top", legend=c("forward", "backward", "centered", "analytical"), col=c("blue", "red", "green", "black"), lty=c(1,1,1,3), bty="n")
title(main='Numerical and analytical solution compared')
grid()
```
</span>

<div class="answer">
```{r}
# Initial parameter values
left  = 0     # left x-coordinate
right = 2*pi  # right x-coordinate
dx    = pi/6  # delta x; space discretisation 

# Simulation initialisation
space.sequence = seq(left, right, by=dx)
dsdx.forward = rep(0, length(space.sequence))
dsdx.backward = rep(0, length(space.sequence))
dsdx.centered = rep(0, length(space.sequence))
s = sin(space.sequence)

# Add the calculations of forward, backward, centered derivative below.
dsdx.forward [1:(length(s)-1)] = (s[2:length(s)] - s[1:(length(s)-1)]) / dx
dsdx.backward[2:length(s)]     = (s[2:length(s)] - s[1:(length(s)-1)]) / dx
dsdx.centered[2:(length(s)-1)] = (s[3:length(s)] - s[1:(length(s)-2)]) / (2*dx)

# Add the boundaries on the left
dsdx.backward[1] = (s[2]-s[1]) / dx
dsdx.centered[1] = (s[2]-s[1]) / dx

# Add the boundaries on the right
dsdx.forward [length(s)] = (s[length(s)]-s[length(s)-1]) / dx
dsdx.centered[length(s)] = (s[length(s)]-s[length(s)-1]) / dx

# Plotting
plot(space.sequence, dsdx.forward, type='o', xlab="x (m)", ylab="dsdx", ylim = c(-1.5, 1.5), col="blue")
lines(space.sequence, dsdx.backward, type='o', col="red")
lines(space.sequence, dsdx.centered, type='o', col="green")
space.sequence = seq(left, right, by=0.01)
analyt.state = cos(space.sequence)
lines(space.sequence, analyt.state, col='black', lty=3)
legend("top", legend=c("forward", "backward", "centered", "analytical"), col=c("blue", "red", "green", "black"), lty=c(1,1,1,3), bty="n")
title(main='Numerical and analytical solution compared')
grid()
```

The centered method performs better than the other two. When dx is decreased, all three methods finally converge to the correct solution, but the centered method converges much faster.
</div>

# Part 2 - Matrix calculation intermezzo
### Section 2.1
Further in this tutorial, and the next one, we will use matrix algebra intensively. This part is a short tutorial in working with matrices in the R environment.

A formal definition of a matrix is a collection of numbers organized in rows and columns. The following lines of codes construct a matrix:

```{R}
M = matrix (c(1, 2, 3, 4, 5, 6) , nrow=2)
print(M)
```

The code lines above made a matrix by giving all the values in the construction itself. Once constructed, values of a matrix can be changed in different ways.

<span class="exercise">
2.1.1 How many rows and how many columns has this matrix?
</span>

<span class="answer">
2 rows, 3 columns
</answer>

<span class="exercise">
2.1.2 Describe for each of the following lines the changes made to the matrix M.
```{R}
M[1,2]= 100
M[1, ]= c(10, 11, 12)
M[ ,2]= c(-1 ,-2)
```
</span>

<span class="exercise">
2.1.3 What is the difference between the matrix constructed above and the matrix constructed by:
```{R}
M = matrix(c(1, 2, 3, 4, 5, 6), nrow=2 , ncol=3)
```
</span>

<span class="exercise">
2.1.4 What is the difference between the first matrix and the matrix constructed by:
```{R}
M = matrix(c(1, 2, 3, 4, 5, 6) , nrow=2 , ncol=2)
```
</span>

<span class="exercise">
2.1.5 What is the difference between the first matrix and the matrix constructed by:
```{R}
M = matrix(c(1, 2, 3, 4, 5, 6) , nrow=2 , ncol=4)
```
</span>

<span class="exercise">
2.1.6 What is the difference between the first matrix and the matrix constructed by:
```{R}
M = matrix(c(1, 2, 3, 4, 5, 6) , nrow=2 , ncol=3 , byrow=TRUE)
```
</span>

### Section 2.2
The matrix constructions in the previous exercise were very explicit. Many
matrices (certainly large ones) can more efficiently be constructed by loops. The following lines of code give an example (and prints the result):

```{R}
M = matrix(0, nrow=5, ncol=7)
for(i in 1:nrow(M)) {
  for(j in 1:ncol(M)) {
    M[i,j]=i+j
  }
}
print(M)
```

<span class="exercise">
2.2.1 Make code with a double loop as above that constructs the following matrix:

```{}
> print(M)
     [,1] [,2] [,3] [,4] [,5]
[1,]   11   12   13   14   15
[2,]   21   22   23   24   25
[3,]   31   32   33   34   35
```
</span>

<span class="answer">
```{R}
M = matrix(0,nrow=3,ncol=5)
for(i in 1:nrow(M)) {
  for(j in 1:ncol(M)){
    M[i,j]=10*i+j
  }
}
print(M)
```
</span>

<span class="exercise">
2.2.2 Make code with a double loop as above that constructs the following matrix:

```{}
> print(M)
     [,1][,2][,3][,4][,5]
[1,]    0   1   2   3   4
[2,]    1   0   1   2   3
[3,]    2   1   0   1   2
[4,]    3   2   1   0   1
[5,]    4   3   2   1   0
```
</span>

<span class="answer">
```{R}
M = matrix(0,nrow=5,ncol=5)
for(i in 1:nrow(M)) {
  for(j in 1:ncol(M)){
    M[i,j]=abs(i-j)
  }
}
print(M)
```
</span>

### Section 2.3
These exercise are an introduction to the solution of linear equations. The following linear equations:

$$
\begin{align}
 2x_1 + x_2 -  x_3 = 8\\
-3x_1 - x_2 + 2x_3 = -11\\
-2x_1 + x_2 + 2x_3 = -3
\end{align}
$$
are rewritten in matrix form:

$$
\begin{matrix}
A\ x &=& b\\
\begin{bmatrix}
2&1&-1\\-3&-1&2\\-2&1&2
\end{bmatrix}
\begin{bmatrix}
x_1\\x_2\\x_2
\end{bmatrix}
&=&
\begin{bmatrix}
8\\-11\\-3
\end{bmatrix}
\end{matrix}
$$
This system of equations can be solved in the following way, where $I$ is the [identity matrix](https://en.wikipedia.org/wiki/Identity_matrix).
$$
Ax = b\\
A^{-1}Ax = A^{-1}b\\
Ix = A^{-1}b\\
x = A^{-1}b
$$
By hand this can be done with [Gaussian elimination](https://en.wikipedia.org/wiki/Gaussian_elimination). If unfamiliar with this method or if in need of a quick refresher, the following video might be instructive: https://www.youtube.com/watch?v=xCIXkm3-ocQ 

R can also directly solve for $x$, given the matrices A and b:

```{}
x = solve(A,b)
```

<span class="exercise">
2.3.1 Find the solution of the above system of equations first by hand and check your solution by solving it in R.
</span>

<span class="answer">
$$
\begin{bmatrix}
x_1\\x_2\\x_2
\end{bmatrix} = 
\begin{bmatrix}
2\\3\\-1
\end{bmatrix}
$$
</span>

<span class="exercise">
2.3.2 Find the solution with R (as done above) of the following equations:
$$
\begin{align}
x_1 = 4\\
-x_1 + 2x_2 - x_3 = 1\\
-x_2 + 2x_3 - x_4 = 1\\
-x_3 + 2x_4 - x_5 = 1\\
x_5 = 2
\end{align}
$$
</span>

<span class="answer">
```{R}
A = matrix(c(1,0,0,0,0,-1,2,-1,0,0,0,-1,2,-1,0,0,0,-1,2,-1,0,0,0,0,1),nrow=5,ncol=5,byrow=TRUE)
b = matrix(c(4,1,1,1,2),nrow=5)
print(solve(A,b))
```
</span>

The equations above can be generalized for any integer N into:
$$ 
\begin{matrix}
& &&x_1 &=& 4\\
&\ i\ \in\ \left[2, N-1 \right] && -x_{i-1} + 2x_i-x_{i+1} &=& 1\\
& &&x_N &=& 2
\end{matrix}
$$

Write code that generates the matrices for the equations above and
solves them. Use the following lines as a starter:

```{R}
N = 5
A = matrix(0,nrow=N,ncol=N)
b = rep(1,length=N)
```

<span class="exercise">
2.3.3 Finish this code.
<br><br>
2.3.4 Check that for N=5 the result of the previous exercise is recalculated.
<br><br>
2.3.5 Make a plot of the result for N=25.
</span>

<span class="answer">
```{R}
N      = 25
A      = matrix(0,nrow=N,ncol=N)
b      = rep(1,length=N)
A[1,1] = 1
b[1]   = 4
b[N]   = 2
A[N,N] = 1
for(i in 2:(N-1)){
  A[i,i  ] = 2
  A[i,i-1] = -1
  A[i,i+1] = -1
}
print(solve(A,b))
plot(solve(A,b))
```
</span>

### Section 2.4
In this section the translation of (stationary, discrete) flow problems into a set of linear equations is reviewed.

In what follows, flow problems will be defined by graphs such as:
</br>
![](example_1.png){width=30%}

* The circles stand for cylinders with unknown fluid level for which a name is suggested inside the circle ($x_i$).
* Some of the levels inside the cylinders are prescribed (as is the case in the top cylinder of the example above); these prescribed values are boundary conditions.
* The cylinders are connected with pipes, whose cross sectional areas are indicated inside the pipes by numbers. The flux between these cylinders is given by this area times the level differences between the cylinders connected.
* There can be external amounts of fluids added to the cylinders, as, for instance, the flux with number 3 to the top.

The fluxes between the cylinders are calculated by multiplying the difference between the two cylinders and the cross sectional area. For example between $x_1$ and $x_2$ there is the following flow:

$$q_{1\to2} = 7(x_1-x_2)$$
which is equal to the flux going in the other direction:
$$q_{2\to1} = 7(x_2-x_1)$$
<span class="exercise">
2.4.1 Write down the other fluxes in the system (both forward and backward through the pipe)
</span>

<span class="answer">
$$
\begin{align}
q_{2\to3} &= 8(x_2-x_3)\\
q_{3\to2} &= 8(x_3-x_2)\\
\\
q_{3\to1} &= 5(x_3-x_1)\\
q_{1\to3} &= 5(x_1-x_3)
\end{align}
$$
</span>

From these equations mass balances can be set up, assuming that the system is in a stationary state. For example for cylinder $x_1$:

$$
\begin{align}
q_{2\to1} + q_{3\to1} + 3 = 0 \\
7(x_2-x_1) + 5(x_3-x_1) + 3 = 0
\end{align}
$$
<span class="exercise">
2.4.2 Set up the mass balances for $x_2$ and $x_3$.
</span>

<span class="answer">
$$
\begin{align}
q_{3\to2} + q_{1\to2} + 1 = 0 \\
8(x_3-x_2) + 7(x_1-x_2) + 1 = 0\\
\\
q_{1\to3} + q_{2\to3} + 2 = 0 \\
5(x_1-x_3) + 8(x_2-x_3) + 2 = 0\\
\end{align}
$$
</span>

<span class="exercise">
2.4.3 Write the previous three mass balance equations in the form:
$$ax_1 + bx_2 + cx_3 = d$$
</span>

<span class="answer">
$$
\begin{align}
-12x_1 + 7x_2 + 5x_3 = -3\\
7x_1 - 15x_2 + 8x_3 = -1\\
5x_1 + 8x_2 -13x_3 = -2
\end{align}
$$
</span>

<span class="exercise">
2.4.4 Plug the previous equations in an A and b matrix in the following way:

$$
\begin{align}
Ax &= b\\
\begin{bmatrix}
a_{1} & b_{1} & c_{1}\\a_{2} & b_{2} & c_{2}\\a_{3} & b_{3} & c_{3}
\end{bmatrix} \cdot
\begin{bmatrix}
x_1\\x_2\\x_3
\end{bmatrix} &=
\begin{bmatrix}
d_1\\d_2\\d_3
\end{bmatrix}
\end{align}
$$
</span>

<span class="answer">
$$
\begin{align}
\begin{bmatrix}
-12&7&5\\7&-15&8\\5&8&-13
\end{bmatrix} *
\begin{bmatrix}
x_1\\x_2\\x_3
\end{bmatrix} &=
\begin{bmatrix}
-3\\-1\\-2
\end{bmatrix}
\end{align}
$$
</span>

<span class="exercise">
2.4.5 Put the boundary condition $x_1 = 2$ into the matrix.
</span>

<span class="answer">
$$
\begin{align}
\begin{bmatrix}
1&0&0\\7&-15&8\\5&8&-13
\end{bmatrix} *
\begin{bmatrix}
x_1\\x_2\\x_3
\end{bmatrix} &=
\begin{bmatrix}
2\\-1\\-2
\end{bmatrix}
\end{align}
$$
</span>

<span class="exercise">
2.4.6 Implement these matrices in R and let R find the x vector.
</span>

<span class="answer">
```{R}
M=matrix(0,nrow=3,ncol=3)
# bring flux between 1and 2 in matrix
M[1,1] = M[1,1]-7
M[1,2] = M[1,2]+7
M[2,2] = M[2,2]-7
M[2,1] = M[2,1]+7
# bring flux between 1 and 3 in matrix
M[1,1] = M[1,1]-5
M[1,3] = M[1,3]+5
M[3,3] = M[3,3]-5
M[3,1] = M[3,1]+5
# bring flux between 2 and 3 in matrix
M[2,2] = M[2,2]-8
M[2,3] = M[2,3]+8
M[3,3] = M[3,3]-8
M[3,2] = M[3,2]+8
# bring in the boundary condition
M[1,]  = 0
M[1,1] = 1
# right hand side
b = c(2,-1,-2)
print(solve(M,b))
```
</span>

<span class="exercise">
2.4.7 Solve the system depicted in the following scheme and explain the result: 
</br>

![](example_2.png){width=30%}

</span>

<div class="answer">
```{R}
M=matrix(0,nrow=3,ncol=3)
# bring flux between 1and 2 in matrix
M[1,1] = M[1,1]-7
M[1,2] = M[1,2]+7
M[2,2] = M[2,2]-7
M[2,1] = M[2,1]+7
# bring flux between 1 and 3 in matrix
M[1,1] = M[1,1]-5
M[1,3] = M[1,3]+5
M[3,3] = M[3,3]-5
M[3,1] = M[3,1]+5
# bring flux between 2 and 3 in matrix
M[2,2] = M[2,2]-8
M[2,3] = M[2,3]+8
M[3,3] = M[3,3]-8
M[3,2] = M[3,2]+8
# bring in the boundary condition
M[1,]  = 0
M[1,1] = 1
# right hand side
b = c(2,0,0)
print(solve(M,b))
```
There is nothing to disturb the system, so it will become a static state with a uniform final state.
</div>

This is the easiest way of implementing and solving systems with matrices. There are, however, smarter and faster ways of doing this. 

*For a challenging exercise, go to **Exercise 1** in the `Finite_difference_2_extra.Rmd` file.*

<span class="comment">
Exercise 6 in the pdf could be useful
</span>

# Part 3 - Bringing matrix algebra and finite differences together

## Section 3.1 - The first-order derivative
In part 1, you have computed the derivatives in an intuitive way, using multiplication and additions of vectors. You can also compute derivatives in a more general way, using matrices. This is a very powerful technique, because it permits the solution of steady state systems, as well as for an easy extension towards system that vary in space and time, such as the advection-diffusion equation.

Let's first look at the case of Part 1.2: the sinus wave. Let us assume that we do not know the derivative and use finite differences to compute the spatial derivative (The "observations" are in fact calculated with the function $f = \sin(x)$ and therefore the exact solution is known: a cosine wave).

We aim to write the computation of the derivative in the form

$$
M*s = v
$$
where the matrix $M$ contains the operation that performs the derivative on vector $s$ (the states), such that vector $v$ contains the derivative $ds/dx$ at each point. We therefore call the matrix of coefficients contained in $M$ the *operator*. Remember that each line in the matrix contains an equation.    
In this case, we have a row of N nodes in space (i=1 to N) with states $s_{1}$ to $s_{N}$. In case of the forward differencing method, the first line of the matrix contains the coefficients of the equation
$$
\dfrac{s_2 - s_1}{\Delta x} = \left.\dfrac{ds}{dx} \right|_1
$$
In other words, we compute the derivative $(ds/dx)_1$ based on the values of $s_1$ and $s_2$. This generalizes to $(s_{i+1} - s_i)/\Delta x = (ds/dx)_i$. For a vector of $N$ elements, you will get a $N \times N$ matrix.

<span class="exercise">
3.1.1 Fill in the matrix below for a system of five nodes (a $5 \times 5$ forward differencing operator)
</span>

<span class="student_answer">
$$
\begin{bmatrix}
&.&.&.&.\\
&.&.&.&.\\
&.&.&.&.\\
&.&.&.&.\\
&.&.&.&.
\end{bmatrix}
\cdot 
\begin{bmatrix}
s_1\\ 
s_2\\ 
s_3\\ 
s_4\\ 
s_5
\end{bmatrix}
= 
\begin{bmatrix}
(ds/dx)_1\\ 
(ds/dx)_2\\ 
(ds/dx)_3\\ 
(ds/dx)_4\\ 
(ds/dx)_5
\end{bmatrix}
$$
</span>

<span class="answer">
$$
\begin{bmatrix}
&\frac{-1}{\Delta x}&\frac{1}{\Delta x}&.&.&.\\
&.&\frac{-1}{\Delta x}&\frac{1}{\Delta x}&.&.\\
&.&.&\frac{-1}{\Delta x}&\frac{1}{\Delta x}&.\\
&.&.&.&\frac{-1}{\Delta x}&\frac{1}{\Delta x}\\
&.&.&.&\frac{-1}{\Delta x}&\frac{1}{\Delta x}
\end{bmatrix}
\cdot 
\begin{bmatrix}
s_1\\ 
s_2\\ 
s_3\\ 
s_4\\ 
s_5
\end{bmatrix}
= 
\begin{bmatrix}
(ds/dx)_1\\ 
(ds/dx)_2\\ 
(ds/dx)_3\\ 
(ds/dx)_4\\ 
(ds/dx)_5
\end{bmatrix}
$$
</span>

Now, you will implement this problem into a piece of code. Note that we are not trying to find the vector $s$, but the derivatives vector $v$. Therefore, we do not need the `solve` function of R yet, but we can use matrix multiplication $M*s$ to find $v$. Note that in R matrix multiplication is performed as follows: `M %*% s`.

<span class="exercise">
3.1.2 Complete the code block below, and compare your results against the analytical solution.
</span>

<span class="student_answer">
```{r forward_derivative, eval=FALSE}
rm(list=ls()) 

# setting up initial parameters
dx    = pi/2
left  = 0
right = 2*pi
xcoor = seq(left, right, by=dx) # builds a list of all coordinates

M = matrix(0, nrow=length(xcoor), ncol=length(xcoor)) # an empty matrix for the differencing scheme
v = rep(0, length(xcoor))

s = sin(xcoor) # the original sinus series that needs to be differentiated

# populating vector and matrix
# WRITE A LOOP TO FILL THE MATRIX

# Apply the derivative operator using matrix multiplication.
# FIND THE VECTOR V

# plotting
N = length(xcoor)
plot(xcoor, v, ylab="derivative", xlab="x (m)", type='o', col='blue', ylim = c(-1.5,1.5), xlim = c(0,2*pi)) # numerical approximation
x_sol = seq(left, right, by=0.05)
lines(x_sol, cos(x_sol), type='l', col="grey", lwd=2)
title(main='Forward differencing scheme with matrices')
grid()
```
</span>

<span class="answer">

```{r forward_derivative_answer}
rm(list=ls()) 

# setting up initial parameters
dx    = pi/2
left  = 0
right = 2*pi
xcoor = seq(left, right, by=dx) # builds a list of all coordinates

M = matrix(0, nrow=length(xcoor), ncol=length(xcoor)) # an empty matrix for the differencing scheme
v = rep(0, length(xcoor))

s = sin(xcoor) # the original sinus series that needs to be differentiated

# populating vector and matrix
nx = length(xcoor)
for (j in 1:(nx-1))
{
  M[j,j+1] = +1/dx
  M[j,j]   = -1/dx
}
M[nx,nx]   = +1/dx
M[nx,nx-1] = -1/dx

# Apply the derivative operator using matrix multiplication.
v = M %*% s

# plotting
N = length(xcoor)
plot(xcoor, v, ylab="derivative", xlab="x (m)", type='o', col='blue', ylim = c(-1.5,1.5), xlim = c(0,2*pi)) # numerical approximation
x_sol = seq(left, right, by=0.05)
lines(x_sol, cos(x_sol), type='l', col="grey", lwd=2)
title(main='Forward differencing scheme with matrices')
grid()
```
</span>

<span class="exercise">
3.1.4 Implement the backward and central scheme in the same way as in the previous exercise and plot them together in the same plot using different colors.
</span>

<span class="student answer">
```{r all_derivatives, eval=FALSE}
rm(list=ls()) 

# setting up initial parameters
dx    = pi/2
left  = 0
right = 2*pi
xcoor = seq(left, right, by=dx) # builds a list of all coordinates

M_forward = matrix(0, nrow=length(xcoor), ncol=length(xcoor)) # an empty matrix 
v_forward = rep(0, length(xcoor))

M_backward = matrix(0, nrow=length(xcoor), ncol=length(xcoor)) # an empty matrix 
v_backward = rep(0, length(xcoor))

M_centered = matrix(0, nrow=length(xcoor), ncol=length(xcoor)) # an empty matrix 
v_centered = rep(0, length(xcoor))

s = sin(xcoor) # the original sinus series that needs to be differentiated

# populating vector and matrix
# WRITE A LOOP (OR MULTIPLE LOOPS) TO FILL THE MATRICES

# Apply the derivative operator using matrix multiplication.
# CALCULATE THE DERIVATIVES HERE

# plotting
N = length(xcoor)
plot(xcoor, v_forward, ylab="derivative", xlab="x (m)", type='o', col='blue', ylim = c(-1.5,1.5), xlim = c(0, 2*pi)) # numerical approximation
# ADD THE OTHER TWO LINES
x_sol = seq(left, right, by=0.05)
lines(x_sol, cos(x_sol), type='l', col="grey", lwd=2)
title(main='Differencing scheme with matrices')
grid()
# legend(XXXX)
```
</span>

<span class="answer">
```{r all_derivatives_answers}
rm(list=ls()) 

# setting up initial parameters
dx    = pi/2
left  = 0
right = 2*pi
xcoor = seq(left, right, by=dx) # builds a list of all coordinates

M_forward = matrix(0, nrow=length(xcoor), ncol=length(xcoor)) # an empty matrix 
v_forward = rep(0, length(xcoor))

M_backward = matrix(0, nrow=length(xcoor), ncol=length(xcoor)) # an empty matrix 
v_backward = rep(0, length(xcoor))

M_centered = matrix(0, nrow=length(xcoor), ncol=length(xcoor)) # an empty matrix 
v_centered = rep(0, length(xcoor))

s = sin(xcoor) # the original sinus series that needs to be differentiated

# populating vector and matrix
nx = length(xcoor)

# forward
for (j in 1:(nx-1))
{
  M_forward[j,j+1] = +1/dx
  M_forward[j,j]   = -1/dx
}
M_forward[nx,nx]   = +1/dx
M_forward[nx,nx-1] = -1/dx

# backward
M_backward[1,2] = +1/dx
M_backward[1,1] = -1/dx
for (j in 2:nx)
{
  M_backward[j,j]   = +1/dx
  M_backward[j,j-1] = -1/dx
}

# centered
M_centered[1,2] = +1/dx
M_centered[1,1] = -1/dx
for (j in 2:(nx-1))
{
  M_centered[j,j+1] = +1/(2*dx)
  M_centered[j,j-1] = -1/(2*dx)
}
M_centered[nx,nx]   = +1/dx
M_centered[nx,nx-1] = -1/dx

# Apply the derivative operator using matrix multiplication.
v_forward  = M_forward  %*% s
v_backward = M_backward %*% s
v_centered = M_centered %*% s

# plotting
N = length(xcoor)
plot(xcoor, v_forward, ylab="derivative", xlab="x (m)", type='o', col='blue', ylim = c(-1.5,1.5), xlim = c(0, 2*pi)) # numerical approximation
lines(xcoor, v_backward, type='o', col='red') # numerical approximation
lines(xcoor, v_centered, type='o', col='green') # numerical approximation
x_sol = seq(left, right, by=0.05)
lines(x_sol, cos(x_sol), type='l', col="grey", lwd=2)
title(main='Differencing scheme with matrices')
grid()
legend(0,-1.2,c("forward","backward","centered","analytical"),col=c("blue","red","green","grey"),lwd=c(1,1,1,2),horiz=TRUE,cex=0.8)
```
</span>

To evaluate the quality of these different approaches you can compare the summed absolute error between the approximated and real values.    
*If you are up for a challenging exercise, where you will numerically derive the errors, you can open **Exercise 2** from the `Finite_differences_2_extended.Rmd` file. If not, you can continue here.* 

<span class="exercise">
3.1.5 Fill the following table of errors by running the chunk below.
</span>

<div class="student_answer">

| dx | Forward differencing scheme | Central differencing scheme |
| ------------- | ------------- | ------------- |
| $\pi$ |  |  |
| $\frac{1}{2}\pi$ |  |  |
| $\frac{1}{3}\pi$ |  |  |
| $\frac{1}{4}\pi$ |  |  |
| $\frac{1}{5}\pi$ |  |  |
| $\frac{1}{10}\pi$ |  |  |
| $\frac{1}{20}\pi$ |  |  |
</div>

<button type="button" onclick="toggle('Q2')">Show chunk</button>

<div id="Q2" style="display: none">
```{r calculate_error_differencing_schemes, eval=F}
rm(list=ls()) 
library(shiny)

f = function(scheme = "C", dx=(pi/2)){
  
  # scheme C = central
  # scheme F = forward
  
  #### setting up initial parameters
  dx    = dx
  left  = 0
  right = 2*pi
  xcoor = seq(left,right, by=dx) # builds a list of all coordinates
  N     = length(xcoor)
  s     = sin(xcoor)
  c     = cos(xcoor)
  
  ##### CENTRAL SCHEME WITH FORWARD AND BACKWARD VALUES ON THE OUTER NODES
  
  M     = matrix(0,nrow=length(xcoor),ncol=length(xcoor)) # an empty matrix for the differencing scheme
  
  # populating vector and matrix
  for(j in 2:(length(xcoor)-1))
  {
    M[j,j+1] = 1/(2*dx)
    M[j,j-1] = -1/(2*dx)
  }
  M[1,1  ] = -1/dx
  M[1,2  ] = 1/dx
  M[N,N  ] = 1/dx
  M[N,N-1] = -1/dx
  
  # solve matrix equation
  V_c = M %*% s
  
  ##### FORWARD SCHEME WITH BACKWARD RIGHT NODE
  
  M     = matrix(0,nrow=length(xcoor),ncol=length(xcoor)) # an empty matrix for the differencing scheme
  
  # populating vector and matrix
  for(j in 1:(length(xcoor)-1))
  {
    M[j,j]   = -1/dx
    M[j,j+1] = 1/dx
  }
  M[N,N  ] = 1/dx
  M[N,N-1] = -1/dx
  
  # solve matrix equation
  V_f = M %*% s
  
  ##### PLOTTING
  if(scheme == "C"){
    ## plotting C
    plot(xcoor[1:(N)],V_c[1:(N)], ylab="state (m)", xlab="x (m) ", type='o', col='blue', ylim=c(-1.5,1.5), xlim = c(0,2*pi)) # numerical approximation
    x_sol = seq(left,right,by=0.05)
    lines(x_sol,cos(x_sol),type='l', col="grey", lwd=2)
    
    # including error and 
    error = mean(abs(c-V_c))
    for(i in 1:N){
      points(xcoor[i],V_c[i],col="green",pch=19)
      points(xcoor[i],c[i],pch=19)
      segments(xcoor[i],V_c[i],xcoor[i],c[i],col="red",lwd=2)
    }
    
    title(main=paste('Central scheme, error = ', as.character(round(error,6))))
    grid()
  }
  
  ## plotting F
  if(scheme == "F"){
    plot(xcoor[1:(N)],V_f[1:(N)],ylab="state (m)",xlab="x (m) ",type='o',col='blue', ylim=c(-1.5,1.5), xlim = c(0,2*pi)) # numerical approximation
    x_sol = seq(left,right,by=0.05)
    lines(x_sol,cos(x_sol),type='l', col="grey",lwd=2)
    grid()
    
    # including error and 
    error = mean(abs(c-V_f))
    for(i in 1:N){
      points(xcoor[i],V_f[i],col="green",pch=19)
      points(xcoor[i],c[i],pch=19)
      segments(xcoor[i],V_f[i],xcoor[i],c[i],col="red",lwd=2)
    }
    
    title(main=paste('Forward scheme, error = ',as.character(round(error,3))))
    grid()
  }
}

#########################################
ui <- fluidPage(
  
  # App title ----
  titlePanel("Calculate the error"),
  
  # Sidebar layout with input and output definitions ----
  sidebarLayout(
    
    # Sidebar panel for inputs ----
    sidebarPanel(
      
      selectInput("scheme", label="scheme", choices = list("Central differencing scheme"="C","Forward differencing scheme"="F")),
      sliderInput("dx", label  = HTML("dx (<sup>&Pi;</sup>&frasl;<sub>x</sub>):") , value=2, min = 1, max = 20, step = 1)
    ),
    
    # Main panel for displaying outputs ----
    mainPanel(
      
      # Output: Plot of the requested variable against mpg ----
      plotOutput("p")
    )
  )
)
server <- function(input, output) {
  output$p = renderPlot({f(scheme = input$scheme, dx = pi/(input$dx))})
}

shinyApp(ui, server)
```
</div>

<div class="answer">
| dx | Forward differencing scheme | Central differencing scheme |
| ------------- | ------------- | ------------- |
| $\pi$ | 1 | 1 |
| $\frac{1}{2}\pi$ | 0.47 | 0.22 |
| $\frac{1}{3}\pi$ | 0.31 | 0.12 |
| $\frac{1}{4}\pi$ | 0.23 | 0.065 |
| $\frac{1}{5}\pi$ | 0.19 | 0.044 |
| $\frac{1}{10}\pi$ | 0.096 | 0.011 |
| $\frac{1}{20}\pi$ | 0.049 | 0.0026 |
</div>

<span class="exercise">
3.1.6 Which scheme convergest fastest? Can you calculate the convergence rate (the error reduction per doubling of the number of grid points from the numbers)? Does this fit with the theory?
</span>

<div class="answer">
The centered difference scheme clearly converges faster.  
Looking at the table, the forward scheme reduces its error by about 0.5 each time the number of nodes is doubled. For the centered sheme, this is closer to 0.25. This faster convergence corresponds to the theory set out in section 1.2: the centered scheme has second-order convergence.
```{r}
#forward
forward_rate=mean(c(0.47/1,0.23/0.47,0.096/0.19,0.049/0.096))
centered_rate=mean(c(0.22/1,0.065/0.22,0.011/0.044,0.0026/0.011))
```
</div>

## Section 3.2 - Second order derivative
In order to be able to solve the *stationary* advection diffusion equation later, there is still one other thing to be explained: how to compute the second order derivative in the equation

$$0 = -u \frac{\partial s}{\partial x} + D\frac{\partial^{2}s}{\partial x^{2}}$$
Also the *second* derivative finite differences operator can be derived from the Taylor series. To do so, we need to combine the forward and backward differencing methods that are written below:

\begin{align*}
s(x + \Delta x) & = s(x) + \dfrac{\Delta x}{1!} \dfrac{ds}{dx} \bigg\rvert_{x} + \dfrac{(\Delta x)^{2}}{2!} \dfrac{d^{2}s}{dx^{2}} \bigg\rvert_{x} + \dfrac{(\Delta x)^{3}}{3!} \dfrac{d^{3}s}{dx^{3}} \bigg\rvert_{x} + \dfrac{(\Delta x)^{4}}{4!} \dfrac{d^{4}s}{dx^{4}} \bigg\rvert_{x} + \ \cdots \\    

s(x - \Delta x) & = s(x) - \dfrac{\Delta x}{1!} \dfrac{ds}{dx} \bigg\rvert_{x} + \dfrac{(\Delta x)^{2}}{2!} \dfrac{d^{2}s}{dx^{2}} \bigg\rvert_{x} - \dfrac{(\Delta x)^{3}}{3!} \dfrac{d^{3}s}{dx^{3}} \bigg\rvert_{x} + \dfrac{(\Delta x)^{4}}{4!} \dfrac{d^{4}s}{dx^{4}} \bigg\rvert_{x} - \ \cdots
\end{align*}

<div class="exercise">
3.2.1 Combine the two equations such that the term containing the first derivative falls out of the equation. 
</div>

<div class="answer">
$$
s(x + \Delta x) + s(x - \Delta x)
= 2 s(x) + (\Delta x)^2 \dfrac{d^{2}s}{dx^{2}} + \dfrac{(\Delta x)^2}{12} \dfrac{d^4 s}{dx^4}
$$
</div>

<div class="exercise">
3.2.2 Rewrite the equation such, that the operator (thus all instances of $s(x-\Delta x)$, $s(x)$, and $s(x+\Delta x)$) is on the lefthand side, and on the righthand side are only the second derivative and the error.
</div>

<div class="answer">
$$
\dfrac{ s(x + \Delta x) - 2s(x) + s(x - \Delta x)}{(\Delta x)^2} 
= \dfrac{d^{2}s}{dx^{2}} + \dfrac{(\Delta x)^2}{12} \dfrac{d^4 s}{dx^4}
$$
</div>

<div class="exercise">
3.2.3 Use the derived equation to construct a matrix that can be used to compute the second derivative for all x-nodes. Copy your previous `forward_derivative` chunk below (Tip: you can navigate through the markdown with the button in the bottom of the editor window). Adapt the code to produce the second derivative. Keep in mind that you also have to prescribe the correct analytical solution!
</div>

<div class="student_answer">
Implement your code here.
```{r}
# WHOOP WHOOP NEW CODE
```
</div>

<div class="answer">
```{r central_second_derivative}
rm(list=ls()) 

# setting up initial parameters
dx    = pi/2
left  = 0
right = 2*pi
xcoor = seq(left,right, by=dx) # builds a list of all coordinates
s = sin(xcoor)

nx = length(xcoor)

M = matrix(0, nrow=nx, ncol=nx) # an empty matrix for the differencing scheme

# populating vector and matrix
for (j in 2:(nx-1))
{
  M[j,j+1] = 1/(dx^2)
  M[j,j  ] = -2/(dx^2)
  M[j,j-1] = 1/(dx^2)
}

# Compute the second derivative
v = M %*% s

# plotting
plot(xcoor[2:(nx-1)], v[2:(nx-1)], ylab="2nd derivative", xlab="x (m) ", type='o', col='blue', ylim=c(-1.5,1.5), xlim = c(0,2*pi)) # numerical approximation
x_sol = seq(left,right,by=0.05)
lines(x_sol,-sin(x_sol),type='l', col="grey",lwd=2)
title(main='Second derivative computed with matrices')
grid()
```
</div>

# Part 4: Solving equations using matrix inversions.
Before solving the advection diffusion equation directly, you will learn how to combine the spatial operators and the matrix inversion that you have learned before. 

Imagine now, that rather than knowing the state $s(x)$ of the system, you know the values of the first derivative at each node. Assuming that the value of the derivative is given by $\cos(x)$, we can invert the system to acquire the values of $s(x)$ at each node. Let us assume, we use the forward differencing operator as worked out in *exercise 3.1.2*.

We can now define the system as a set of equations in the form
$$
M s = v
$$
where $v$ in this case is the the vector $( (ds/dx)_1, (ds/dx)_2, \ldots, (ds/dx)_n)$. In order to acquire the state vector $s$, we need to apply matrix algebra.

<div class="exercise">
4.1.1 Write out the matrix operations that provide the values of $s$.
</div>

<div class="answer">
$$
\begin{matrix}
M  s &=& v\\
M^{-1}M s &=& M^{-1}v\\
I s &=& M^{-1}v\\
s &=& M^{-1}v
\end{matrix}
$$
</div>

Now, you will put the mathematics above into code.

<div class="exercise">
4.1.2 Implement the matrix $M$ that contains the spatial operator, work out the vector $v$ that contains the derivatives evaluated using $\cos(x)$, and use these two to solve for $s$. Note that in this case you do need the `solve` function of R.

4.1.3 Most likely, the developed system does not solve, because you did not implement a boundary condition. Fix the value at $x = 2 \pi$ (the last node) to $0$ and solve it again. Does the system converge to the correct solution if you decrease `dx`?
</div>

<div class="student_answer">
Work out the code below:
```{r forward_derivative_inversion, eval=FALSE}
rm(list=ls()) 

# setting up initial parameters
dx    = pi/2
left  = 0
right = 2*pi
xcoor = seq(left, right, by=dx) # builds a list of all coordinates

M = matrix(0, nrow=length(xcoor), ncol=length(xcoor)) # an empty matrix for the differencing scheme

# DEFINE THE VECTOR v WHICH CONTAINS THE DERIVATIVES.

# CREATE THE MATRIX.
nx = length(xcoor)
# use a loop to fill the matrix

# SOLVE THE SYSTEM IN ORDER TO ACQUIRE THE VECTOR s WHICH CONTAINS THE STATE.

# plotting
plot(xcoor, s, ylab="state (m)", xlab="x (m)", type='o', col='blue', ylim = c(-1.5,1.5), xlim = c(0,2*pi)) # numerical approximation
x_sol = seq(left, right, by=0.05)

# ADD A THICK GREY LINE CONTAINING THE ANALYTICAL SOLUTION.

title(main='Inversion of the forward finite difference operator')
grid()
```
</div>

<div class="answer">
```{r forward_derivative_inversion_answer}
rm(list=ls()) 

# setting up initial parameters
dx    = pi/2
left  = 0
right = 2*pi
xcoor = seq(left, right, by=dx) # builds a list of all coordinates

M = matrix(0, nrow=length(xcoor), ncol=length(xcoor)) # an empty matrix for the differencing scheme
v = cos(xcoor)

# populating vector and matrix
nx = length(xcoor)
for (j in 1:(nx-1))
{
  M[j,j+1] = +1/dx
  M[j,j]   = -1/dx
}

M[nx,nx] = 1  #boundary condition
v[nx] = sin(xcoor[nx])

# Apply the derivative operator using matrix multiplication.
s = solve(M,v)

# plotting
plot(xcoor, s, ylab="state (m)", xlab="x (m)", type='o', col='blue', ylim = c(-1.5,1.5), xlim = c(0,2*pi)) # numerical approximation
x_sol = seq(left, right, by=0.05)
lines(x_sol, sin(x_sol), type='l', col="grey", lwd=2)
title(main='Inversion of the forward finite difference operator')
grid()
```
</div>

# Part 5 - Solving the advection-diffusion equation.
## Section 5.1 - Boundary conditions
In the final part of the exercise, you will apply everything that you have learned in order to solve the advection diffusion equation. The steady-state advection-diffusion equation
$$
0 = -u \dfrac{ds}{dx} + D \dfrac{d^2s}{dx^2}
$$
contains both first- and second-order derivatives. In order to solve such an equation, you need to apply boundary conditions, in order to make the matrix invertible. So far we have only implemented one type of boundary condition; the **Dirichlet boundary condition**. This method assumes a fixed state at one or all boundaries. If the state directly next to this border has (more or less) the same state, it means that there is no flux over the boundary, whereas a large difference leads to a large flux. 

Another option is to implement a so-called **Neumann boundary condition** in which the gradient is fixed. Such a boundary condition is often used if we desire to control the flux through the boundary. The final type of boundary condition is the **Cauchy/Robin boundary condition**, in which both the state and the gradient are specified. To summarize, the three possible boundary conditions are:

* Dirichlet (fixed state: $s = c$)
* Neumann (fixed gradient $ds/dx = c$)
* Cauchy/Robin (fixed state and fixed gradient $as + b\,ds/dx = c$)

<span class="comment">
This is a quick summary of boundary conditions, but do we want to give it like this or should the students find this out for themselves?
Esther: Giving it is ok I think, it is not the most important message here
</span>

## Section 5.2 - Implementation with Dirichlet boundary conditions
<div class="exercise">
5.2.1 Work out (pen and paper or $\LaTeX$) the stationary advection-diffusion equation (given at the beginning of this section) with 5 nodes (n=5) and two Dirichlet boundaries (left=0 and right=1) in the following notation:

$$
\begin{bmatrix}
M_{1,1}&&\dots&&M_{1,n}\\
&&&&\\
\vdots&&\ddots&&\vdots\\
&&&&\\
M_{n,1}&&\dots&&M_{n,n}\\
\end{bmatrix} * 
\begin{bmatrix}
s_1\\
s_2\\
s_3\\
s_4\\
s_5\\
\end{bmatrix} = 
\begin{bmatrix}
v_1\\
v_2\\
v_3\\
v_4\\
v_5\\
\end{bmatrix}
$$
TIP: remember that a boundary condition is just an equation that replaces one in the matrix.
</div>

<div class="answer">
$$
\begin{bmatrix}
1&.&.&.&.\\
-\frac{u}{2dx} - \frac{D}{dx^2}&\frac{2D}{dx^2}&\frac{u}{2dx} - \frac{D}{dx^2}&.&.\\
.&-\frac{u}{2dx} - \frac{D}{dx^2}&\frac{2D}{dx^2}&\frac{u}{2dx} - \frac{D}{dx^2}&.\\
.&.&-\frac{u}{2dx} - \frac{D}{dx^2}&\frac{2D}{dx^2}&\frac{u}{2dx} - \frac{D}{dx^2}\\
.&.&.&.&1
\end{bmatrix} * 
\begin{bmatrix}
s_1\\
s_2\\
s_3\\
s_4\\
s_5\\
\end{bmatrix} = 
\begin{bmatrix}
b_l\\
v_2\\
v_3\\
v_4\\
b_r\\
\end{bmatrix}
$$
</div>

*If you want to go deeper into the subject and implement the whole solver yourself, go to **Exercise 3** of the `Finite_differences_2_extra.Rmd` and skip the two following exercises here (going on with 5.2.4).*

<span class="exercise">
5.2.2 Calculate the values in the matrix with $\Delta x = 5$, $D=5$ and $u=5$ and check if the following chunk yields the same matrix.
```{R}
dx    = 5    # step size
D     = 5    # diffusion coefficient
u     = 5    # advection coefficient
bl    = 0    # left boundary
br    = 1    # right boundary
n     = 5    # amount of nodes

left  = 0    # left coordinate
xcoor = seq(left,dx*(n-1), by=dx)

v     = c()  # build an empty vector for the derivatives
M     = matrix(0, nrow=length(xcoor), ncol=length(xcoor)) 

for(j in 2:(length(xcoor)-1))
{
  M[j,j-1] = -u/(2*dx) - D/(dx^2)
  M[j,j  ] = 2*D/(dx^2)
  M[j,j+1] = u/(2*dx) - D/(dx^2)
  v[j]     = 0
}

# Left boundary
M[1,1] = 1
v[1]   = bl

# Right boundary
M[n,n] = 1
v[n]   = br

# Solve the system
s = solve(M,v)

print(M)
```
</span>

<span class="exercise">
5.2.3 Run the following chunk to see the quality of the solution:
```{R}
dx    = 5    # step size
D     = 5    # diffusion coefficient
u     = 5    # advection coefficient
bl    = 0    # left boundary
br    = 1    # right boundary
n     = 5    # amount of nodes

left  = 0    # left coordinate
xcoor = seq(left,dx*(n-1), by=dx)

v     = c()  # build an empty vector for the derivatives
M     = matrix(0, nrow=length(xcoor), ncol=length(xcoor)) 

for(j in 2:(length(xcoor)-1))
{
  M[j,j-1] = -u/(2*dx) - D/(dx^2)
  M[j,j  ] = 2*D/(dx^2)
  M[j,j+1] = u/(2*dx) - D/(dx^2)
  v[j]     = 0
}

# Left boundary
M[1,1] = 1
v[1]   = bl

# Right boundary
M[n,n] = 1
v[n]   = br

# Solve the system
s = solve(M,v)

# Plotting
plot(xcoor,s,ylab="state (m)",xlab="x (m) ",type='o',col='blue')
title(main='Advection Diffusion Equation')
grid()

# Calculate and plot the analytical solution
L = dx*(n-1)
xcooranalyt = seq(0,L, by=0.01)
sanalyt = c()
Danalyt = D
uanalyt = u
Peanalyt = uanalyt*L/Danalyt

for(j in 1:(length(xcooranalyt)))
{
  sanalyt[j] = bl+(exp(xcooranalyt[j]*Peanalyt/L)-1.)/(exp(Peanalyt)-1.)*(br-bl)
}

lines(xcooranalyt,sanalyt,col="grey",lwd=2) # analytical solution
legend(10, 0.8, c("numerical", "analytical"), col = c("blue","grey"), lty = c(1,1), pch = c(-1,-1))
```
</span>

<span class="exercise"> 
5.2.4 The following chunk is the same system as analysed in the previous exercise. The only difference is that the domain is increased to x=50. Change `dx` from 10 to 1 in steps of 1 and compare the results. What is the highest value of `dx` for which the solution is stable?
```{R}
dx    = 10   # step size
D     = 5    # diffusion coefficient
u     = 5    # advectio coefficient
bl    = 0    # left boundary
br    = 1    # right boundary

left  = 0    # left coordinate
right = 50
xcoor = seq(left,right, by=dx)

v     = c()  # build an empty vector for the derivatives
M     = matrix(0,nrow=length(xcoor),ncol=length(xcoor)) 

for(j in 2:(length(xcoor)-1))
{
  M[j,j-1] = -u/(2*dx) - D/(dx^2)
  M[j,j  ] = 2*D/(dx^2)
  M[j,j+1] = u/(2*dx) - D/(dx^2)
  v[j]     = 0
}

# Left boundary
M[1,1] = 1
v[1]   = bl

# Right boundary
n = length(xcoor)
M[n,n] = 1
v[n]   = br

# Solve the system
s = solve(M,v)

# Plotting
plot(xcoor,s,ylab="state (m)",xlab="x (m) ",type='o',col='blue')
title(main='Advection Diffusion Equation')
grid()

# Calculate and plot the analytical solution
L = dx*(n-1)
xcooranalyt = seq(0,L, by=0.01)
sanalyt = c()
Danalyt = D
uanalyt = u
Peanalyt = uanalyt*L/Danalyt

for(j in 1:(length(xcooranalyt)))
{
  sanalyt[j] = bl+(exp(xcooranalyt[j]*Peanalyt/L)-1.)/(exp(Peanalyt)-1.)*(br-bl)
}

lines(xcooranalyt,sanalyt,col="grey",lwd=2) # analytical solution
legend(10, 0.8, c("numerical", "analytical"), col = c("blue","grey"), lty = c(1,1), pch = c(-1,-1))
```

<span class="answer">
The solution becomes stable starting from dx=2 and below.
</span>

## Section 5.3 - Implementation with a Neumann boundary condition
Here, you will work out the Neumann boundary condition case.    
*If you are motivated for a challenging exercise, you can open **Exercise 4** of the `Finite_differences_2_extra.Rmd` and skip the remainder of this section.*

As an example we will look at a Neumann boundary with a gradient of $0.5$. In mathematical terms this means:

$$
\dfrac{ds}{dx} = 0.5
$$
We would like to introduce this boundary condition at the right side of our domain.

<div class="exercise">
5.3.1 Work the boundary condition into the matrix $M$ of the previous exercise, such that the Dirichlet boundary condition is replaced by the Neumann boundary conditions. Do this using pen-and-paper or using $\LaTeX$.
</div>

<div class="answer">
$$
\dfrac{ds}{dx} = \dfrac{s[5]-s[4]}{\Delta x}\\
s[5] - s[4] = 0.5 * \Delta x = \frac{\Delta x}{2}
$$

and inserted in the matrix:

$$
\begin{bmatrix}
1&.&.&.&.\\
-\frac{u}{2dx} - \frac{D}{dx^2}&\frac{2D}{dx^2}&\frac{u}{2dx} - \frac{D}{dx^2}&.&.\\
.&-\frac{u}{2dx} - \frac{D}{dx^2}&\frac{2D}{dx^2}&\frac{u}{2dx} - \frac{D}{dx^2}&.\\
.&.&-\frac{u}{2dx} - \frac{D}{dx^2}&\frac{2D}{dx^2}&\frac{u}{2dx} - \frac{D}{dx^2}\\
.&.&.&-1&1
\end{bmatrix} * 
\begin{bmatrix}
s_1\\
s_2\\
s_3\\
s_4\\
s_5\\
\end{bmatrix} = 
\begin{bmatrix}
b_l\\
V_2\\
V_3\\
V_4\\
b_r = \frac{\Delta x}{2}\\
\end{bmatrix}
$$
</div>

<div class="exercise">
5.3.2 What do you think the states will now look like? Test your hypothesis by completing the following chunk to incorporate the Neumann boundary condition (change the XXX's in the code).

5.3.3 For which grid spacing `dx` does the solution become smooth? Can you explain this?

5.3.4 What happens if you decrease D (for instance to 1)? Do you need a finer `dx` or can you use a coarser one? Why?
</div>

<div class="student_answer">
```{R, eval=F}
dx    = 5    # step size
D     = 5    # diffusion coefficient
u     = 5    # advection coefficient
bl    = 0    # left boundary
br    = XXX  # right boundary

left  = 0    # left coordinate
right = 50
xcoor = seq(left,right, by=dx)
N     = length(xcoor)

v     = c()  # build an empty vector for the derivatives
M     = matrix(0,nrow=length(xcoor),ncol=length(xcoor)) 

for(j in 2:(length(xcoor)-1))
{
  M[j,j-1] = -u/(2*dx) - D/(dx^2)
  M[j,j  ] = 2*D/(dx^2)
  M[j,j+1] = u/(2*dx) - D/(dx^2)
  v[j]     = 0
}

# Boundary conditions
XXX

# Solve the system
s = solve(M,v)

# Plotting
plot(xcoor,s,ylab="state (m)",xlab="x (m) ",type='o',col='blue')
title(main='Advection Diffusion Equation, Neumann boundary')
grid()
```
</span>

<span class="answer">
```{R}
dx    = 5    # step size
D     = 5    # diffusion coefficient
u     = 5    # advection coefficient
bl    = 0    # left boundary
br    = dx/2 # right boundary

left  = 0    # left coordinate
right = 50
xcoor = seq(left,right, by=dx)
N     = length(xcoor)

v     = c()  # build an empty vector for the derivatives
M     = matrix(0,nrow=length(xcoor),ncol=length(xcoor)) 

for(j in 2:(length(xcoor)-1))
{
  M[j,j-1] = -u/(2*dx) - D/(dx^2)
  M[j,j  ] = 2*D/(dx^2)
  M[j,j+1] = u/(2*dx) - D/(dx^2)
  v[j]     = 0
}

# Left boundary
M[1,1] = 1
v[1]   = bl

# Right boundary

M[N,N]   = 1
M[N,N-1] = -1
v[N]     = br

# Solve the system
s = solve(M,v)

# Plotting
plot(xcoor,s,ylab="state (m)",xlab="x (m) ",type='o',col='blue')
title(main='Advection Diffusion Equation, Neumann boundary')
grid()
```

From about dx=1 and below, the solution follows a smooth line. When D is decreased to 1, a much *smaller* dx is needed. This can be explained by looking at the advection-diffusion equation. This equation consists of an advection part, governed by the first derivative in space, and a diffusion part, governed by the second derivative. If D is decreased, the advection part becomes more dominant. As we have seen, the solutions of the first derivatives converge less fast than those of the second derivative. A smaller dx is therefore needed.
</div>

<span class="comment">
Do we want to implement the FDS/BDS and the UBS here as well?
</span>
