---
title: "Answers to sensitivity-1D exercise 7"
subtitle: "Sample size=1000, seed=238"
output:
   html_document:
    css: want.css
    toc: yes
---

```{r}
rm(list=ls())
library(FVFE1D)
```

# 1. Building the model

## The mathematical setup
First, the 1D groundwater model is built in the same way as the ones you built in earlier practicals.
The first step is choosing the spatial model domain:
```{r}
domain = c(0,500) 
```

The system (internal) flux will be a simple Dupuit flux, with a transmissivity $kD$ 
that changes linearly between the left and right side of the domain.

```{r}
kDl = 55
kDr = 35
kD.fun = approxfun(domain,c(kDl,kDr)) #gives a (linear) function for the transmissivity
# caution: every time you change kDl or kDr you have to reconstruct this function
internal.flux = function(x,state,gradstate) 
  {
  return(-kD.fun(x)*gradstate)
  }
```

The chunk below constructs the new model with the name 'base run':  
```{r}
GWmodel = newFLOW1D(domain,internal.flux) 
set.name(GWmodel,"base run")
```

There is constant recharge flux (rainfall) on top of the model; and an extraction well.  
The recharge is a spatial flux, the extraction well is a point flux.   

```{r}
P = 0.001
add.spatialflux(GWmodel,"P","recharge")
Qwell = -0.35
add.pointflux(GWmodel,at = 275, value= 'Qwell',name = 'well')
```

On the left hand side, the river with a water level of 1 m is used as a boundary condition.
The right hand side is a water divide: a zero flux boundary, which is already applied as the default in the FVFE1D package.

```{r}
hl = 1
set.BC.fixedstate(GWmodel,"left","hl") 
```

## The numerical setup and base run solution
The domain is discretized with nodes and a solution technique. Here the Finite Volume technique is used.

```{r}
nodes = seq(from=domain[1],to=domain[2],length=50) 
set.discretisation(GWmodel,nodes,"FV")
```

```{r}
control = solve.steps(GWmodel)
plot(GWmodel,fluxplot=TRUE) 
```

## Choice of MRESULT

```{r}
MRESULT = function()
{
  XS = dataframe.states(GWmodel)
  MH = mean(XS[(XS$x>125)&(XS$x<200),"state"])
  return(MH)
}
```

Store the results of the base run:
```{r}
M_base = MRESULT()
print(M_base)
state_base = dataframe.states(GWmodel)$state
```

## Parameter values and scales

The parameter values defined before will form the base values:
```{r}
base= list(kDl=kDl,kDr=kDr,P=P,Qwell=Qwell,hl=hl)
str(base)
```

The scales of variation (standard deviation) for the parameters have to be provided by the modeller.
We store these in a list as well:

```{r}
scale= list(kDl = 1*kDl,
            kDr = 7.5*kDr,
            P = 0.25*P,
            Qwell = -0.4*Qwell,
            hl = 0.05)
str(scale)
```

Below we define the epsilon value `eps`, which is the amount by which we will 'disturb' the parameters.

```{r}
eps = 1e-3
```

# 2. Sensitivity analysis

## 2.1 GSA calculations

```{r}
source("samplehelpers.R")
```

**Constructing the parameter sample**

```{r}
parnames = names(base)
parmeans = unlist(base)
parsd    = unlist(scale)
parlower = c(1, 1, 0, -1, 0.5)
parupper = c(1000, 1000, 2, 0, 1.5)
samplesize = 1000
set.seed(238)
parsample = GaussianLHS(samplesize,parmeans,parsd,parnames,parlower,parupper) 
```

The following code shows the first lines of the sample, the statistical summary and a plot:
```{r}
head(parsample)
summary(parsample)
plot(parsample,cex=0.4)
```

We combine here the six histograms of the sampled parameters in one plot:

```{r}
old.par = par(no.readonly=TRUE)
par(mfrow=c(2,3))
par(mar=c(5,5,1,1))
hist(parsample[,"kDl"],main="",col="lightblue",prob=TRUE)
rug(parsample[,"kDl"],col="red")
lines(density(parsample[,"kDl"]),col="red",lwd=2)
hist(parsample[,"kDr"],main="",col="lightblue",prob=TRUE)
rug(parsample[,"kDr"],col="red")
lines(density(parsample[,"kDr"]),col="red",lwd=2)
hist(parsample[,"P"],main="",col="lightblue",prob=TRUE)
rug(parsample[,"P"],col="red")
lines(density(parsample[,"P"]),col="red",lwd=2)
hist(parsample[,"Qwell"],main="",col="lightblue",prob=TRUE)
rug(parsample[,"Qwell"],col="red")
lines(density(parsample[,"Qwell"]),col="red",lwd=2)
hist(parsample[,"hl"],main="",col="lightblue",prob=TRUE)
rug(parsample[,"hl"],col="red")
lines(density(parsample[,"hl"]),col="red",lwd=2)
par(old.par)
```

The distributions of the sampled parameters are very similar between the two seeds.

**Making all the model runs**

We run the model for each parameter set, and store:

1. __All__ the state of each run. 
This may in some applications be too large.
2. The M-values.

```{r}
statesSample = matrix(0,ncol=length(nodes),nrow=0)
Msample = c()
for(i in 1:nrow(parsample))
  {
    kDl = parsample[i,"kDl"]
    kDr = parsample[i,"kDr"]
    P  = parsample[i,"P"]
    Qwell = parsample[i,"Qwell"]
    hl = parsample[i,"hl"]
    kD.fun = approxfun(domain,c(kDl,kDr),rule=2)
    control = solve.steps(GWmodel)
    statesSample = rbind(statesSample,dataframe.states(GWmodel)$state)
    Msample = c(Msample,MRESULT())
  }
```

**A graphical anaysis of the resulting states**

```{r}
library(matrixStats)
```

Plot all the model results of the sampled parameter sets in one plot:

```{r}
matplot(nodes,t(statesSample),type="l",main="States for all parameter sets",ylab="groundwater level")
```

There are still differences between seed=237 and seed=238 in "outlier" model runs. However, these outliers have less influence now. 

The following plot contains:

1. The mean of the calculated states from all parameter sets (as a blue line)
2. Standard deviation intervals (in blue) above and under the mean.
The standard deviation interval for the state for each x contains about 2/3 of all calculated values.  
3. The model result calculated with the mean (base) parameters (as red points)

```{r}
StatesSampleMeans = colMeans(statesSample) #mean of the calculated states at each node
allSDs = colSds(statesSample) #standard deviation of the states at each node
plot(nodes,StatesSampleMeans,col="blue",type="l",lwd=4,ylim=c(-1,3),
     ylab="groundwater level",main="Mean states of GSA (blue) & LSA base run (red)")
lines(nodes,StatesSampleMeans-allSDs,col="blue")
lines(nodes,StatesSampleMeans+allSDs,col="blue")
points(nodes,state_base,pch=10, col="red")
```

It can be seen that the mean model result of all the parameter sets is close to the model results calculated with the mean parameters, but does deviate from it. There are no changes due to the adapted seed.

## 2.2 GSA variation analysis
We will limit the GSA variation analysis to the data calculated by MRESULT.

**Analysis of the M-sample**

First we determine the basic statistics of the M-sample:
```{r}
VARM = var(Msample)
SDM = sd(Msample)
print(paste("variance of sample M",round(VARM,4)))
print(paste("standard deviation of M",round(SDM,4)))
```

Plotting the histogram:
```{r}
smoothdensM = density(Msample)
histdataM = hist(Msample,plot=FALSE)$density
yrange = range(smoothdensM$y,histdataM)
hist(Msample,col="lightblue",prob=TRUE,ylim=yrange)
rug(Msample,col="red")
lines(smoothdensM,col="red",lwd=3)
```

There is still a small difference in the standard deviation of M between the seeds (0.6 vs 0.58). However, the shape of the distribution of M is now very similar between the two.

**Conditional expectation of M with respect to parameters**

Combine the M-sample and the parameter-sample into one big matrix:
```{r}
MPsample = cbind(M=Msample,parsample)
head(MPsample)
```

Next we will approximate the conditional expectation of M given each of the parameters.

```{r}
McondkDl = linloess(M~kDl,data=MPsample)
McondkDr = linloess(M~kDr,data=MPsample)
McondP = linloess(M~P,data=MPsample)
McondQwell = linloess(M~Qwell,data=MPsample)
Mcondhl = linloess(M~hl,data=MPsample)
```

All plots in one overview:

```{r}
old.par = par(no.readonly=TRUE)
par(mfrow=c(2,3))
par(mar=c(5,5,1,1))
plot(MPsample[,"kDl"],MPsample[,"M"])
points(MPsample[,"kDl"],McondkDl,pch=20,col="red")
plot(MPsample[,"kDr"],MPsample[,"M"])
points(MPsample[,"kDr"],McondkDr,pch=20,col="red")
plot(MPsample[,"P"],MPsample[,"M"])
points(MPsample[,"P"],McondP,pch=20,col="red")
plot(MPsample[,"Qwell"],MPsample[,"M"])
points(MPsample[,"Qwell"],McondQwell,pch=20,col="red")
plot(MPsample[,"hl"],MPsample[,"M"])
points(MPsample[,"hl"],Mcondhl,pch=20,col="red")
par(old.par)
```

Seed 237 and seed 238 now give very similar conditional expectation curves.

**Contribution of the parameters to the variance of M**

Use the `sample.vardecomp` function to finish the analysis:

```{r}
ANOVA1 = sample.vardecomp(MPsample)
pie(ANOVA1,
    main=paste("Standard deviation of M =",round(SDM,4),"m"),
    col = rainbow(5),
    radius=1)
print(ANOVA1) # the variance in M caused by each parameter
print(sqrt(ANOVA1)) # the standard deviation of M caused by each parameter
```

The relative contributions of the parameters are now much more equal between the seeds.
