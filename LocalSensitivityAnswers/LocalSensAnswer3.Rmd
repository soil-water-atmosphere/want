---
title: "Answers to local sensitivity exercise 6"
subtitle: "Effect of changing the seed for random sampling"
output:
   html_document:
    css: want.css
    toc: yes
---


```{r}
rm(list=ls())
library(FVFE1D)
```

# 1. Building the model

## The mathematical setup
First, the 1D groundwater model is built in the same way as the ones you built in earlier practicals.
The first step is choosing the spatial model domain:
```{r}
domain = c(0,500) 
```

The system (internal) flux will be a simple Dupuit flux, with a transmissivity $kD$ 
that changes linearly between the left and right side of the domain.

```{r}
kDl = 55
kDr = 35
kD.fun = approxfun(domain,c(kDl,kDr)) #gives a (linear) function for the transmissivity
# caution: every time you change kDl or kDr you have to reconstruct this function
internal.flux = function(x,state,gradstate) 
  {
  return(-kD.fun(x)*gradstate)
  }
```

The chunk below constructs the new model with the name 'base run':  
```{r}
GWmodel = newFLOW1D(domain,internal.flux) 
set.name(GWmodel,"base run")
```

There is constant recharge flux (rainfall) on top of the model; and an extraction well.  
The recharge is a spatial flux, the extraction well is a point flux.   

```{r}
P = 0.001
add.spatialflux(GWmodel,"P","recharge")
Qwell = -0.35
add.pointflux(GWmodel,at = 275, value= 'Qwell',name = 'well')
```

On the left hand side, the river with a water level of 1 m is used as a boundary condition.
The right hand side is a water divide: a zero flux boundary, which is already applied as the default in the FVFE1D package.

```{r}
hl = 1
set.BC.fixedstate(GWmodel,"left","hl") 
```

## The numerical setup and base run solution
The domain is discretized with nodes and a solution technique. Here the Finite Volume technique is used.

```{r}
nodes = seq(from=domain[1],to=domain[2],length=50) 
set.discretisation(GWmodel,nodes,"FV")
```

```{r}
control = solve.steps(GWmodel)
plot(GWmodel,fluxplot=TRUE) 
```

## Choice of MRESULT

```{r}
MRESULT = function()
{
  XS = dataframe.states(GWmodel)
  MH = mean(XS[(XS$x>125)&(XS$x<200),"state"])
  return(MH)
}
```

Store the results of the base run:
```{r}
M_base = MRESULT()
print(M_base)
state_base = dataframe.states(GWmodel)$state
```

## Parameter values and scales

The parameter values defined before will form the base values:
```{r}
base= list(kDl=kDl,kDr=kDr,P=P,Qwell=Qwell,hl=hl)
str(base)
```

The scales of variation (standard deviation) for the parameters have to be provided by the modeller.
We store these in a list as well:

```{r}
scale= list(kDl = 1*kDl,
            kDr = 7.5*kDr,
            P = 0.25*P,
            Qwell = -0.4*Qwell,
            hl = 0.05)
str(scale)
```

Below we define the epsilon value `eps`, which is the amount by which we will 'disturb' the parameters.

```{r}
eps = 1e-3
```

# 2. Sensitivity analysis

## 2.1 AVS calculations

```{r}
source("samplehelpers.R")
```

**Constructing the parameter sample**

```{r}
parnames = names(base)
parmeans = unlist(base)
parsd    = unlist(scale)
parlower = c(1, 1, 0, -1, 0.5)
parupper = c(1000, 1000, 2, 0, 1.5)
samplesize = 300
set.seed(238)
parsample = GaussianLHS(samplesize,parmeans,parsd,parnames,parlower,parupper) 
```

The following code shows the first lines of the sample, the statistical summary and a plot:
```{r}
head(parsample)
summary(parsample)
plot(parsample,cex=0.4)
```

We combine here the six histograms of the sampled parameters in one plot:

```{r}
old.par = par(no.readonly=TRUE)
par(mfrow=c(2,3))
par(mar=c(5,5,1,1))
hist(parsample[,"kDl"],main="",col="lightblue",prob=TRUE)
rug(parsample[,"kDl"],col="red")
lines(density(parsample[,"kDl"]),col="red",lwd=2)
hist(parsample[,"kDr"],main="",col="lightblue",prob=TRUE)
rug(parsample[,"kDr"],col="red")
lines(density(parsample[,"kDr"]),col="red",lwd=2)
hist(parsample[,"P"],main="",col="lightblue",prob=TRUE)
rug(parsample[,"P"],col="red")
lines(density(parsample[,"P"]),col="red",lwd=2)
hist(parsample[,"Qwell"],main="",col="lightblue",prob=TRUE)
rug(parsample[,"Qwell"],col="red")
lines(density(parsample[,"Qwell"]),col="red",lwd=2)
hist(parsample[,"hl"],main="",col="lightblue",prob=TRUE)
rug(parsample[,"hl"],col="red")
lines(density(parsample[,"hl"]),col="red",lwd=2)
par(old.par)
```

The distributions of the sampled parameters are very similar to how they were with seed=237.

**Making all the model runs**

We run the model for each parameter set, and store:

1. __All__ the state of each run. 
This may in some applications be too large.
2. The M-values.

```{r}
statesSample = matrix(0,ncol=length(nodes),nrow=0)
Msample = c()
for(i in 1:nrow(parsample))
  {
    kDl = parsample[i,"kDl"]
    kDr = parsample[i,"kDr"]
    P  = parsample[i,"P"]
    Qwell = parsample[i,"Qwell"]
    hl = parsample[i,"hl"]
    kD.fun = approxfun(domain,c(kDl,kDr),rule=2)
    control = solve.steps(GWmodel)
    statesSample = rbind(statesSample,dataframe.states(GWmodel)$state)
    Msample = c(Msample,MRESULT())
  }
```

**A graphical anaysis of the resulting states**

```{r}
library(matrixStats)
```

Plot all the model results of the sampled parameter sets in one plot:

```{r}
matplot(nodes,t(statesSample),type="l",main="States for all parameter sets",ylab="groundwater level")
```

Some differences in the generated heads are visible, especially in the 'outlier' sample runs. 

The following plot contains:

1. The mean of the calculated states from all parameter sets (as a blue line)
2. Standard deviation intervals (in blue) above and under the mean.
The standard deviation interval for the state for each x contains about 2/3 of all calculated values.  
3. The model result calculated with the mean (base) parameters (as red points)

```{r}
StatesSampleMeans = colMeans(statesSample) #mean of the calculated states at each node
allSDs = colSds(statesSample) #standard deviation of the states at each node
plot(nodes,StatesSampleMeans,col="blue",type="l",lwd=4,ylim=c(-1,3),
     ylab="groundwater level",main="Mean states of AVS (blue) & LSA base run (red)")
lines(nodes,StatesSampleMeans-allSDs,col="blue")
lines(nodes,StatesSampleMeans+allSDs,col="blue")
points(nodes,state_base,pch=10, col="red")
```

It can be seen that the mean model result of all the parameter sets is close to the model results calculated with the mean parameters, but does deviate from it.   
The standard deviation still increases from left to right. There are no changes due to the adapted seed.

## 2.2 AVS variation analysis
We will limit the AVS analysis to the data calculated by MRESULT.

**Analysis of the M-sample**

First we determine the basic statistics of the M-sample:
```{r}
VARM = var(Msample)
SDM = sd(Msample)
print(paste("variance of sample M",round(VARM,4)))
print(paste("standard deviation of M",round(SDM,4)))
```

The standard deviation is higher than with the previous seed.

Plotting the histogram:
```{r}
smoothdensM = density(Msample)
histdataM = hist(Msample,plot=FALSE)$density
yrange = range(smoothdensM$y,histdataM)
hist(Msample,col="lightblue",prob=TRUE,ylim=yrange)
rug(Msample,col="red")
lines(smoothdensM,col="red",lwd=3)
```

The distribution of M has become slightly more narrow and peaky compared to the results with seed=237.

**Conditional expectation of M with respect to parameters**

Combine the M-sample and the parameter-sample into one big matrix:
```{r}
MPsample = cbind(M=Msample,parsample)
head(MPsample)
```

Next we will approximate the conditional expectation of M given each of the parameters.

```{r}
McondkDl = linloess(M~kDl,data=MPsample)
McondkDr = linloess(M~kDr,data=MPsample)
McondP = linloess(M~P,data=MPsample)
McondQwell = linloess(M~Qwell,data=MPsample)
Mcondhl = linloess(M~hl,data=MPsample)
```

All plots in one overview:

```{r}
old.par = par(no.readonly=TRUE)
par(mfrow=c(2,3))
par(mar=c(5,5,1,1))
plot(MPsample[,"kDl"],MPsample[,"M"])
points(MPsample[,"kDl"],McondkDl,pch=20,col="red")
plot(MPsample[,"kDr"],MPsample[,"M"])
points(MPsample[,"kDr"],McondkDr,pch=20,col="red")
plot(MPsample[,"P"],MPsample[,"M"])
points(MPsample[,"P"],McondP,pch=20,col="red")
plot(MPsample[,"Qwell"],MPsample[,"M"])
points(MPsample[,"Qwell"],McondQwell,pch=20,col="red")
plot(MPsample[,"hl"],MPsample[,"M"])
points(MPsample[,"hl"],Mcondhl,pch=20,col="red")
par(old.par)
```

There are some changes to the conditional expectation plots. The conditional density of M to P is less linear than before; also there is a slight increasing trend in the dependence of M on hl, which wasn't visible before.

**Contribution of the parameters to the variance of M**

Use the `sample.vardecomp` function to finish the analysis:

```{r}
ANOVA1 = sample.vardecomp(MPsample)
pie(ANOVA1,
    main=paste("Standard deviation of M =",round(SDM,4),"m"),
    col = rainbow(5),
    radius=1)
print(ANOVA1) # the variance in M caused by each parameter
print(sqrt(ANOVA1)) # the standard deviation of M caused by each parameter
```

Still, the same three most important parameters pop up (Qwell, P, kDl). However, their relative contributions have changed significantly. The contribution of kDl is much smaller than before, while the contribution of P has increased, becoming almost equal to Qwell. The influence of the random number seed is clearly visible here.
